{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_Games_Flair_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO6sDbezOB5ekpOCinDa6ti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chuktuk/Amazon_Customer_Data/blob/master/Video_Games_Flair_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNITLBx8Zjce",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis of Video Game Review from Amazon\n",
        "Chuck Tucker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI5-VWMtZtfT",
        "colab_type": "text"
      },
      "source": [
        "Data from\n",
        "> Justifying recommendations using distantly-labeled reviews and fined-grained aspects Jianmo Ni, Jiacheng Li, Julian McAuley Empirical Methods in Natural Language Processing (EMNLP), 2019\n",
        "[https://nijianmo.github.io/amazon/index.html#files](https://nijianmo.github.io/amazon/index.html#files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VycAs4GY9L2",
        "colab_type": "text"
      },
      "source": [
        "This notebook is designed to run on Google Colab Pro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fherDXSXaQF7",
        "colab_type": "text"
      },
      "source": [
        "### Goal for this analysis\n",
        "\n",
        "The primary purpose of this analysis is to obtain a model that is capable of predicting positive or negative sentiment from analysis of text entries for video game reviews. \n",
        "\n",
        "The reviews were collected by Amazon.com by users after purchasing certain video games. More details on the data set can be obtained by visiting the link above in the 'Data from' section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxauZov5bFRd",
        "colab_type": "text"
      },
      "source": [
        "### Methods and tools\n",
        "\n",
        "The primary text analysis tool displayed here is Flair. First, a model built-in to flair that was pretrained on IMDB reviews was assessed for accuracy on a subset of the video games data.\n",
        "\n",
        "The result of this analysis was unsatisfactory, with extremely low precision on the negative class and an AUC of right around 0.5 (coin flip). \n",
        "\n",
        "Because of the poor performance of the pretrained model, a model was trained on the video games data, which produced much better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBfkOwdnb7RJ",
        "colab_type": "text"
      },
      "source": [
        "### Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PZvmQuWJ_ae",
        "colab_type": "code",
        "outputId": "6010e593-d4dd-4747-a8de-685c33a38417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# check gpu info on Google Colab\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Mar  6 12:02:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBQV7K2KKKvV",
        "colab_type": "code",
        "outputId": "3fb15ae8-375a-4876-b500-db08131f7f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# check RAM info on Google Colab\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w22VQMc-V9jM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import packages\n",
        "import pandas as pd\n",
        "from collections import defaultdict, deque\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFdBDjs1WdPY",
        "colab_type": "code",
        "outputId": "5bbec00d-f71e-450f-afb3-c47ace837a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "# install flair\n",
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.4.5)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.4.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.1)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.7)\n",
            "Requirement already satisfied: pytest>=5.3.2 in /usr/local/lib/python3.6/dist-packages (from flair) (5.3.5)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.7)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: transformers>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from flair) (2.5.1)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.6.1)\n",
            "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.14.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.5.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (8.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (19.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (1.8.1)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.13.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (0.1.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=5.3.2->flair) (20.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.10.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (1.11.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->flair) (2.21.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.3.2->flair) (3.1.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->flair) (7.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->flair) (0.9.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->flair) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (45.2.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers>=2.3.0->flair) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e21SkqIDWQCY",
        "colab_type": "code",
        "outputId": "492d1ee7-3386-450f-85df-ff9d63bae72d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# import flair\n",
        "from flair.models import TextClassifier\n",
        "classifier = TextClassifier.load('en-sentiment')\n",
        "from flair.data import Sentence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q0FBh6LWZoz",
        "colab_type": "code",
        "outputId": "32a3bab5-d56d-4a90-98d1-42e9fd54a447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# load the video games dataset\n",
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-06 11:37:01--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154050105 (147M) [application/octet-stream]\n",
            "Saving to: ‘Video_Games_5.json.gz’\n",
            "\n",
            "Video_Games_5.json. 100%[===================>] 146.91M  10.3MB/s    in 31s     \n",
            "\n",
            "2020-03-06 11:37:33 (4.75 MB/s) - ‘Video_Games_5.json.gz’ saved [154050105/154050105]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1_mzBaIXN-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in the data\n",
        "vg = pd.read_json('Video_Games_5.json.gz', lines=True, compression='gzip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6mMEU8ZXbG5",
        "colab_type": "code",
        "outputId": "97f72aae-8f55-4f02-edbe-d13d00c1f08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# inspect the structure\n",
        "vg.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>10 17, 2015</td>\n",
              "      <td>A1HP7NVNPFMA4N</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>Ambrosia075</td>\n",
              "      <td>This game is a bit hard to get the hang of, bu...</td>\n",
              "      <td>but when you do it's great.</td>\n",
              "      <td>1445040000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>07 27, 2015</td>\n",
              "      <td>A1JGAP0185YJI6</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>travis</td>\n",
              "      <td>I played it a while but it was alright. The st...</td>\n",
              "      <td>But in spite of that it was fun, I liked it</td>\n",
              "      <td>1437955200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>02 23, 2015</td>\n",
              "      <td>A1YJWEXHQBWK2B</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>Vincent G. Mezera</td>\n",
              "      <td>ok game.</td>\n",
              "      <td>Three Stars</td>\n",
              "      <td>1424649600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>02 20, 2015</td>\n",
              "      <td>A2204E1TH211HT</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>Grandma KR</td>\n",
              "      <td>found the game a bit too complicated, not what...</td>\n",
              "      <td>Two Stars</td>\n",
              "      <td>1424390400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>12 25, 2014</td>\n",
              "      <td>A2RF5B5H74JLPE</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>jon</td>\n",
              "      <td>great game, I love it and have played it since...</td>\n",
              "      <td>love this game</td>\n",
              "      <td>1419465600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall  verified   reviewTime  ... vote style image\n",
              "0        5      True  10 17, 2015  ...  NaN   NaN   NaN\n",
              "1        4     False  07 27, 2015  ...  NaN   NaN   NaN\n",
              "2        3      True  02 23, 2015  ...  NaN   NaN   NaN\n",
              "3        2      True  02 20, 2015  ...  NaN   NaN   NaN\n",
              "4        5      True  12 25, 2014  ...  NaN   NaN   NaN\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1xpWVz6XhM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# slice the appropriate columns\n",
        "vg = vg.loc[:,['overall', 'reviewText']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNWBfu3FXn5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean up nan values and change datatype for memory efficiency\n",
        "vg = vg.dropna(how='any')\n",
        "vg.loc[:,'overall'] = vg.overall.astype('int16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZB1HRYWXrnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map sentiment for two-class model\n",
        "vg.loc[:,'pt_sentiment'] = vg.overall.map({1: 0, 2: 0, 3: 1, 4: 1, 5: 1}).astype('int16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te4cU36oX4Gz",
        "colab_type": "code",
        "outputId": "df02d972-dcdb-488b-9107-acb19b73d9b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# inspect the df info\n",
        "vg.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 497419 entries, 0 to 497576\n",
            "Data columns (total 3 columns):\n",
            "overall         497419 non-null int16\n",
            "reviewText      497419 non-null object\n",
            "pt_sentiment    497419 non-null int16\n",
            "dtypes: int16(2), object(1)\n",
            "memory usage: 9.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFqtjP64X87p",
        "colab_type": "code",
        "outputId": "8538ae68-bae7-48a4-a2f6-cdf8a6243617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# get sentiment counts\n",
        "class1_counts = vg.pt_sentiment.value_counts()[1]\n",
        "class0_counts = vg.pt_sentiment.value_counts()[0]\n",
        "print('Positive counts {}'.format(class1_counts))\n",
        "print('Negative counts {}'.format(class0_counts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive counts 442407\n",
            "Negative counts 55012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRUqFQgmcTu5",
        "colab_type": "text"
      },
      "source": [
        "Because the samples were imbalanced, the majority class was downsampled to even out the classes and improve performance of model training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gkLoV3pOTqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import resample\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# down-sample to balance classes\n",
        "vg_class1 = vg[vg.pt_sentiment == 1]\n",
        "vg_class0 = vg[vg.pt_sentiment == 0]\n",
        "\n",
        "# downsample majority class\n",
        "vg_class1_down = resample(vg_class1, replace=False, n_samples=vg_class0.shape[0], random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dygdNkWLRKoj",
        "colab_type": "code",
        "outputId": "fb02c2d4-4470-4d12-e62e-95f8f00c1651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# concat the dfs back together\n",
        "vg_down = pd.concat([vg_class1_down, vg_class0])\n",
        "vg_down.pt_sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    55012\n",
              "0    55012\n",
              "Name: pt_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYtY2iuLceJF",
        "colab_type": "text"
      },
      "source": [
        "Previous exploratory analysis revealed the presence of many special characters. These will be removed from the text prior to training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G4a8iLUUvXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define remove chars function\n",
        "import re\n",
        "\n",
        "def rmv_spec_chars(sentence):\n",
        "    sentence = re.sub(\"[\\\\\\[\\]@_!#$%^&*()<>?/\\|}{~:']\", '', sentence)\n",
        "    sentence = re.sub('-', ' ', sentence)\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FCZaeCAp1g4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean the text\n",
        "vg_down.loc[:,'clean_text'] = vg_down.reviewText.apply(rmv_spec_chars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "265oJjOYqGK8",
        "colab_type": "code",
        "outputId": "78d21918-2247-492c-f94e-1bedb9ac2640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# inspect the result\n",
        "vg_down.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 110024 entries, 388138 to 497576\n",
            "Data columns (total 4 columns):\n",
            "overall         110024 non-null int16\n",
            "reviewText      110024 non-null object\n",
            "pt_sentiment    110024 non-null int16\n",
            "clean_text      110024 non-null object\n",
            "dtypes: int16(2), object(2)\n",
            "memory usage: 2.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1V4Jy0lqKol",
        "colab_type": "code",
        "outputId": "68100d71-f45e-486c-9c70-a6e2434501bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# indicate which text fields are now invalid due to entries that only contain\n",
        "# white space after removal of special characters\n",
        "vg_down.loc[:,'invalid'] = vg_down.clean_text.apply(lambda x: bool(re.match('^\\s+$', x)))\n",
        "vg_down.invalid.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    110020\n",
              "True          4\n",
              "Name: invalid, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG17vF6MlxBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove these from the dataset\n",
        "vg_down = vg_down[vg_down.invalid == False]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFBtUFOWtwYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# identify additional invalid entries that have had every character removed\n",
        "# by the cleaning function (entry was entirely special characters)\n",
        "vg_down.loc[:,'invalid'] = vg_down.clean_text.apply(lambda x: len(x) == 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kXb9pAKuMF1",
        "colab_type": "code",
        "outputId": "6c763de7-01cc-400f-c9b7-08900d69c61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# inspect the number of invalid entries that are empty\n",
        "vg_down.invalid.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    109987\n",
              "True         33\n",
              "Name: invalid, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaqK7A9JuUvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove additional invalid text entries\n",
        "vg_down = vg_down[vg_down.invalid == False]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLiwIhAIlxGw",
        "colab_type": "code",
        "outputId": "b50eebc7-bc04-498f-eecf-d2f40998a442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# classes are still approximately balanced\n",
        "vg_down.pt_sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    55003\n",
              "1    54984\n",
              "Name: pt_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oHi_MVyYEUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the data into train/validation\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(vg_down.clean_text, \n",
        "                                                                    vg_down.pt_sentiment, \n",
        "                                                                    test_size=0.20,\n",
        "                                                                    random_state=42, \n",
        "                                                                    stratify=vg_down.pt_sentiment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuYATGB-nUrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the test data into test/valid\n",
        "valid_text, test_text, valid_labels, test_labels = train_test_split(test_text, test_labels, \n",
        "                                                                      test_size=0.50,\n",
        "                                                                      random_state=42, \n",
        "                                                                      stratify=test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9-2hRhI_ACw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4VLXMie_AN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEFeal4rdrM_",
        "colab_type": "text"
      },
      "source": [
        "The original plan was to test many different chunks if the pretrained model performance was satisfactory at each stage. \n",
        "\n",
        "High performance types from collections were used. Once the first chunk failed, subsequent evaluations were abandoned in interest of training a new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8qSvcsj_AU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testing pretrained model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phMTtwLWYJzi",
        "colab_type": "code",
        "outputId": "37408e2c-c1c8-4b58-9608-49cc913d48c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# split the data into smaller chunks\n",
        "\n",
        "sentences1 = deque()\n",
        "sentences2 = deque()\n",
        "sentences3 = deque()\n",
        "sentences4 = deque()\n",
        "sentences5 = deque()\n",
        "test_text1 = test_text[:25000] # trying smaller size to save memory\n",
        "test_text2 = test_text[25000:50000]\n",
        "test_text3 = test_text[50000:75000]\n",
        "test_text4 = test_text[75000:100000]\n",
        "test_text5 = test_text[100000:]\n",
        "print(len(test_text1) + len(test_text2) + len(test_text3) + len(test_text4) + len(test_text5))\n",
        "print(len(test_text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "124355\n",
            "124355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKGHrCSVYTo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract the first chunk\n",
        "for text in test_text1:\n",
        "    sentences1.append(Sentence(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwurPCuLYedE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_pretrained_preds(sentences):\n",
        "    \n",
        "    # initialize values for loop\n",
        "    scores = defaultdict(float)\n",
        "    values = defaultdict(str)\n",
        "    i = 0\n",
        "    \n",
        "    # predict for all sentences\n",
        "    classifier.predict(sentences, mini_batch_size=32)\n",
        "    \n",
        "    # generate a list of predictions for each text entry\n",
        "    while len(sentences) > 0:\n",
        "        sentence = sentences.popleft()\n",
        "        scores[i] = sentence.labels[0].score\n",
        "        values[i] = sentence.labels[0].value\n",
        "        i+=1\n",
        "        \n",
        "    \n",
        "    # create and return a dataframe from the lists of probabilities and preditions\n",
        "    df = pd.DataFrame({'probability': scores, 'prediction': values})\n",
        "    return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hunjM-B6aStg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create predictions for the first chunk\n",
        "df_pred1 = get_pretrained_preds(sentences1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3BeXbmGaXRn",
        "colab_type": "code",
        "outputId": "394bddd8-ace1-4af9-f184-b9b2235f334c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# inspect the results of the pretrained model's predictions\n",
        "df_pred1.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>probability</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.996104</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.863034</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.999872</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.674651</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.999235</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   probability prediction\n",
              "0     0.996104   POSITIVE\n",
              "1     0.863034   POSITIVE\n",
              "2     0.999872   POSITIVE\n",
              "3     0.674651   POSITIVE\n",
              "4     0.999235   NEGATIVE"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUP7v-qM4kiW",
        "colab_type": "code",
        "outputId": "1a1bdcc9-a0d7-42d4-b179-8d783b22f795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# there are 25000 predictions here\n",
        "df_pred1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myo0WClaYgcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map the text prediction output from the model to 0/1 for comparison to labels\n",
        "df_pred1.loc[:, 'pred'] = df_pred1.prediction.map({'POSITIVE': 1, 'NEGATIVE': 0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq77z6KLYzDi",
        "colab_type": "code",
        "outputId": "0f019d1b-8854-4ad0-89bf-c8b1e8d84613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# inspect\n",
        "df_pred1.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>probability</th>\n",
              "      <th>prediction</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.996104</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.863034</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.999872</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.674651</td>\n",
              "      <td>POSITIVE</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.999235</td>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   probability prediction  pred\n",
              "0     0.996104   POSITIVE     1\n",
              "1     0.863034   POSITIVE     1\n",
              "2     0.999872   POSITIVE     1\n",
              "3     0.674651   POSITIVE     1\n",
              "4     0.999235   NEGATIVE     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCRYcgtkZJrM",
        "colab_type": "code",
        "outputId": "c109ba85-e087-4711-8fab-15613c139cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# get labels to test the accuracy\n",
        "y_true1 = test_labels[:25000,]\n",
        "y_pred1 = df_pred1.loc[:25000, 'pred']\n",
        "print(y_true1.shape)\n",
        "print(y_pred1.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n",
            "(25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjSqxmybZvfX",
        "colab_type": "code",
        "outputId": "63bbbbe2-076c-419c-eeaf-a0c248ccee87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# print the confusion matrix\n",
        "print(confusion_matrix(y_true1, y_pred1))\n",
        "tn, fp, fn, tp = confusion_matrix(y_true1, y_pred1).ravel()\n",
        "dr = tp / (tp + fn)\n",
        "fpr = fp / (fp + tn)\n",
        "print('True Negatives: {}'.format(tn))\n",
        "print('False Positives: {}'.format(fp))\n",
        "print('False Negatives: {}'.format(fn))\n",
        "print('True Positives: {}'.format(tp))\n",
        "print('Detection Rate: {}'.format(dr))\n",
        "print('False Positive Rate: {}'.format(fpr))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2060   681]\n",
            " [ 5285 16974]]\n",
            "True Negatives: 2060\n",
            "False Positives: 681\n",
            "False Negatives: 5285\n",
            "True Positives: 16974\n",
            "Detection Rate: 0.7625679500426794\n",
            "False Positive Rate: 0.24844947099598685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Y8E8Joevy8",
        "colab_type": "text"
      },
      "source": [
        "Over 20% of the predictions were false negatives (5285/25000). While true positives seemed to perform well, the negative predictions were very poor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjsG1h8Ga15K",
        "colab_type": "code",
        "outputId": "6b350e9e-b98a-4f4b-9367-d2fd9d214e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(classification_report(y_true1, y_pred1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.75      0.41      2741\n",
            "           1       0.96      0.76      0.85     22259\n",
            "\n",
            "    accuracy                           0.76     25000\n",
            "   macro avg       0.62      0.76      0.63     25000\n",
            "weighted avg       0.89      0.76      0.80     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ygt5lU4fCXP",
        "colab_type": "text"
      },
      "source": [
        "The classification report illustrates the poor performance of the IMDB pretrained model on the video game reviews with a precision of 0.28 for the negative class and an F1 score of just 0.41."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdcn-2xQbibE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zWc9dGjbfzk",
        "colab_type": "code",
        "outputId": "bbacae0d-444c-4969-f45c-05b1c65f2064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# generate ROC/AUC curve\n",
        "y_pred_prob = df_pred1.probability\n",
        "\n",
        "# unpack into false positive rate, true positive rate, and thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_true1, df_pred1.probability)\n",
        "\n",
        "_ = plt.plot([0,1], [0,1], 'k--')\n",
        "_ = plt.plot(fpr, tpr, label='test_set_1')\n",
        "_ = plt.xlabel('False Positive Rate')\n",
        "_ = plt.ylabel('True Positive Rate')\n",
        "_ = plt.title('Test Set 1 ROC Curve')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nn7NEYIwxfu7/ANez3QO1dyFDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSU_KH8qfT4W",
        "colab_type": "text"
      },
      "source": [
        "Yeah, so this is bad. You want to see the line going way up into the top left of this plot. Generating the integral for the area under the curve shows an AUC of right around 0.50, which is pretty horrible. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXE70qRWcROo",
        "colab_type": "code",
        "outputId": "1f73cd3a-4f37-4dc9-9718-1fc981f731bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# compute the AUC\n",
        "print(roc_auc_score(y_true1, y_pred_prob))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.49359414510466393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmdp5glJc_Am",
        "colab_type": "code",
        "outputId": "fadb66ae-7889-44d0-8d85-eea1d234413d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# plot the precision/recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(y_true1, y_pred_prob)\n",
        "\n",
        "_ = plt.plot(recall, precision)\n",
        "_ = plt.plot([1,0], [0,1], 'k--')\n",
        "_ = plt.xlabel('Recall')\n",
        "_ = plt.ylabel('Precision')\n",
        "_ = plt.title('Precision/Recall Curve')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1O4ufzffm3a",
        "colab_type": "text"
      },
      "source": [
        "Precision/recall is very odd, and appears to show no major decrease in precision as the recall increases. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ETSogt8XJZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions were saved in a file due to the length of time it takes to generate these predictions\n",
        "df_pred1.to_csv('predictions.txt', sep=',', columns=['probability', 'prediction', 'pred'], \n",
        "                header=True, index=True, mode='w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeuXjOs8bMuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_cZbeRR_F0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdTVuftT_F4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLtSVNw3_F8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2fKmBvpgb1N",
        "colab_type": "text"
      },
      "source": [
        "### Manual model training\n",
        "\n",
        "A model was trained using the video games data to try and increase model effectiveness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQPZBUb6dQ9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# manual model training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V179PtJZdQ64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write trianing data to file\n",
        "# format for flair is below\n",
        "# '__label__X Here is the text for the review'\n",
        "# where 'X' is the label for the review (0 is negative, 1 is positive)\n",
        "import os.path\n",
        "\n",
        "idxs = train_text.index.values\n",
        "max_idx = max(idxs)\n",
        "\n",
        "if os.path.isfile('train.txt'):\n",
        "    print (\"File already created.\")\n",
        "else:\n",
        "    with open('train.txt', 'w') as file:\n",
        "        for idx in idxs:\n",
        "            line = '__label__'\n",
        "            line += str(train_labels[idx]) + ' '\n",
        "            line += str.replace(train_text[idx], '\\n', ' ')\n",
        "            line += '\\n'\n",
        "            file.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4AOGzDnempD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write dev.txt\n",
        "max_idx = max(valid_text.index.values)\n",
        "\n",
        "if os.path.isfile('dev.txt'):\n",
        "    print (\"File already created.\")\n",
        "else:\n",
        "    with open('dev.txt', 'w') as file:\n",
        "        for idx in valid_text.index.values:\n",
        "            line = '__label__'\n",
        "            line += str(valid_labels[idx]) + ' '\n",
        "            line += str.replace(valid_text[idx], '\\n', ' ')\n",
        "            line += '\\n'\n",
        "            file.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzYWvHfPduhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write test.txt\n",
        "import os.path\n",
        "\n",
        "max_idx = max(test_text.index.values)\n",
        "\n",
        "if os.path.isfile('test.txt'):\n",
        "    print (\"File already created.\")\n",
        "else:\n",
        "    with open('test.txt', 'w') as file:\n",
        "        for idx in test_text.index.values:\n",
        "            line = '__label__'\n",
        "            line += str(test_labels[idx]) + ' '\n",
        "            line += str.replace(test_text[idx], '\\n', ' ')\n",
        "            line += '\\n'\n",
        "            file.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zs1wk8GkbOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary packages\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ClassificationCorpus\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJoxUVFTQTtP",
        "colab_type": "code",
        "outputId": "79747810-7ac7-490f-9438-5afe3d9609e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check for GPU availability\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx_H5-TWQAR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set storage and GPU usage\n",
        "import flair\n",
        "device = torch.device('cuda:0')\n",
        "map_location=lambda storage, loc: storage.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFH0vcdkiSZ",
        "colab_type": "code",
        "outputId": "e2c800e9-cd15-4153-fb1c-3c13f240ba7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# create corpus containing training, test and dev data\n",
        "corpus: Corpus = ClassificationCorpus('./',\n",
        "                                      test_file='test.txt',\n",
        "                                      dev_file='dev.txt',\n",
        "                                      train_file='train.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:04:04,963 Reading data from .\n",
            "2020-03-06 12:04:04,964 Train: train.txt\n",
            "2020-03-06 12:04:04,965 Dev: dev.txt\n",
            "2020-03-06 12:04:04,966 Test: test.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbH84dyYoaf4",
        "colab_type": "code",
        "outputId": "f36f8a28-415a-41fa-e540-4d61139d61fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(corpus)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "flair.datasets.ClassificationCorpus"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B58JDz5LodEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouF7bUX3oieE",
        "colab_type": "code",
        "outputId": "55738b51-7b26-4910-fc85-70a5f79474af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# generate label dictionary\n",
        "# fails if there are text entries that are invalid\n",
        "# (see removal of invalid entries above)\n",
        "label_dictionary=corpus.make_label_dictionary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:04:08,825 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 87989/87989 [02:00<00:00, 728.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:06:09,856 [b'0', b'1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAp1sAmSkxB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import embeddings\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings, DocumentRNNEmbeddings\n",
        "from typing import List"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41HWFz33k85h",
        "colab_type": "code",
        "outputId": "e5c2b8d5-8050-443c-e877-3c66953adc29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# create word embeddings\n",
        "word_embeddings = [WordEmbeddings('glove'), FlairEmbeddings('news-forward-fast'), \n",
        "                   FlairEmbeddings('news-backward-fast')]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:06:42,392 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmps22mmdnm\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:07<00:00, 21643320.42B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:06:50,340 copying /tmp/tmps22mmdnm to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:06:50,474 removing temp file /tmp/tmps22mmdnm\n",
            "2020-03-06 12:06:53,690 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/glove.gensim not found in cache, downloading to /tmp/tmpocvo3o07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 13293235.60B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:06:55,850 copying /tmp/tmpocvo3o07 to cache at /root/.flair/embeddings/glove.gensim\n",
            "2020-03-06 12:06:55,876 removing temp file /tmp/tmpocvo3o07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:06:58,037 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-forward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmpb0n2u7n5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:01<00:00, 13768414.46B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:07:00,036 copying /tmp/tmpb0n2u7n5 to cache at /root/.flair/embeddings/lm-news-english-forward-1024-v0.2rc.pt\n",
            "2020-03-06 12:07:00,053 removing temp file /tmp/tmpb0n2u7n5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:07:10,278 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmp5or7bv9h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:01<00:00, 12988348.27B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:07:12,300 copying /tmp/tmp5or7bv9h to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2020-03-06 12:07:12,320 removing temp file /tmp/tmp5or7bv9h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08e0-1TglAoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# build the RNN document embeddings\n",
        "document_embeddings = DocumentRNNEmbeddings(word_embeddings, hidden_size=512, \n",
        "                                            reproject_words=True, reproject_words_dimension=256,\n",
        "                                            rnn_type='LSTM')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrMGol1-lHBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the classifier\n",
        "classifier = TextClassifier(document_embeddings, \n",
        "                            label_dictionary=label_dictionary, \n",
        "                            multi_label=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLKUNdNSlLBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a model trainer\n",
        "trainer = ModelTrainer(classifier, corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkaWGTe7lO9w",
        "colab_type": "code",
        "outputId": "d4af82b9-fc03-40c9-b2a5-4be57587ab1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the model\n",
        "# takes approx 12.5 hours to train on Google Colab using Pro GPU\n",
        "trainer.train('./', max_epochs=10, monitor_test=True, embeddings_storage_mode='gpu')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-06 12:07:23,458 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 12:07:23,459 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): WordEmbeddings('glove')\n",
            "      (list_embedding_1): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (list_embedding_2): FlairEmbeddings(\n",
            "        (lm): LanguageModel(\n",
            "          (drop): Dropout(p=0.25, inplace=False)\n",
            "          (encoder): Embedding(275, 100)\n",
            "          (rnn): LSTM(100, 1024)\n",
            "          (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)\n",
            "    (rnn): LSTM(256, 512, batch_first=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (decoder): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-03-06 12:07:23,462 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 12:07:23,463 Corpus: \"Corpus: 87989 train + 10999 dev + 10999 test sentences\"\n",
            "2020-03-06 12:07:23,464 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 12:07:23,465 Parameters:\n",
            "2020-03-06 12:07:23,465  - learning_rate: \"0.1\"\n",
            "2020-03-06 12:07:23,466  - mini_batch_size: \"32\"\n",
            "2020-03-06 12:07:23,467  - patience: \"3\"\n",
            "2020-03-06 12:07:23,468  - anneal_factor: \"0.5\"\n",
            "2020-03-06 12:07:23,469  - max_epochs: \"10\"\n",
            "2020-03-06 12:07:23,470  - shuffle: \"True\"\n",
            "2020-03-06 12:07:23,471  - train_with_dev: \"False\"\n",
            "2020-03-06 12:07:23,472  - batch_growth_annealing: \"False\"\n",
            "2020-03-06 12:07:23,472 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 12:07:23,473 Model training base path: \".\"\n",
            "2020-03-06 12:07:23,474 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 12:07:23,474 Device: cuda:0\n",
            "2020-03-06 12:07:23,475 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 12:07:23,476 Embeddings storage mode: gpu\n",
            "2020-03-06 12:07:23,477 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 12:13:44,190 epoch 1 - iter 275/2750 - loss 0.66566965 - samples/sec: 23.96\n",
            "2020-03-06 12:20:30,629 epoch 1 - iter 550/2750 - loss 0.65452393 - samples/sec: 22.36\n",
            "2020-03-06 12:27:07,126 epoch 1 - iter 825/2750 - loss 0.64385663 - samples/sec: 22.99\n",
            "2020-03-06 12:33:28,559 epoch 1 - iter 1100/2750 - loss 0.63625566 - samples/sec: 23.90\n",
            "2020-03-06 12:39:38,366 epoch 1 - iter 1375/2750 - loss 0.62994053 - samples/sec: 24.75\n",
            "2020-03-06 12:45:43,649 epoch 1 - iter 1650/2750 - loss 0.62482286 - samples/sec: 25.00\n",
            "2020-03-06 12:51:46,546 epoch 1 - iter 1925/2750 - loss 0.61980767 - samples/sec: 25.21\n",
            "2020-03-06 12:58:07,475 epoch 1 - iter 2200/2750 - loss 0.61622284 - samples/sec: 24.01\n",
            "2020-03-06 13:04:25,410 epoch 1 - iter 2475/2750 - loss 0.61324672 - samples/sec: 24.12\n",
            "2020-03-06 13:10:42,196 epoch 1 - iter 2750/2750 - loss 0.60989976 - samples/sec: 24.11\n",
            "2020-03-06 13:10:42,337 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 13:10:42,338 EPOCH 1 done: loss 0.6099 - lr 0.1000\n",
            "2020-03-06 13:18:31,287 DEV : loss 0.5848524570465088 - score 0.7052\n",
            "2020-03-06 13:25:57,318 TEST : loss 0.5844477415084839 - score 0.7115\n",
            "2020-03-06 13:26:04,701 BAD EPOCHS (no improvement): 0\n",
            "2020-03-06 13:26:07,481 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 13:32:21,394 epoch 2 - iter 275/2750 - loss 0.57263743 - samples/sec: 24.35\n",
            "2020-03-06 13:38:54,499 epoch 2 - iter 550/2750 - loss 0.57209893 - samples/sec: 23.18\n",
            "2020-03-06 13:45:02,111 epoch 2 - iter 825/2750 - loss 0.56993982 - samples/sec: 24.66\n",
            "2020-03-06 13:51:49,999 epoch 2 - iter 1100/2750 - loss 0.56610347 - samples/sec: 22.38\n",
            "2020-03-06 13:58:10,677 epoch 2 - iter 1375/2750 - loss 0.56562912 - samples/sec: 23.94\n",
            "2020-03-06 14:04:26,170 epoch 2 - iter 1650/2750 - loss 0.56145454 - samples/sec: 24.30\n",
            "2020-03-06 14:10:42,591 epoch 2 - iter 1925/2750 - loss 0.55970724 - samples/sec: 24.21\n",
            "2020-03-06 14:17:09,330 epoch 2 - iter 2200/2750 - loss 0.56047132 - samples/sec: 23.57\n",
            "2020-03-06 14:23:44,258 epoch 2 - iter 2475/2750 - loss 0.55787197 - samples/sec: 23.18\n",
            "2020-03-06 14:30:21,029 epoch 2 - iter 2750/2750 - loss 0.55767002 - samples/sec: 22.98\n",
            "2020-03-06 14:30:21,216 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 14:30:21,217 EPOCH 2 done: loss 0.5577 - lr 0.1000\n",
            "2020-03-06 14:38:17,699 DEV : loss 0.4969259202480316 - score 0.7824\n",
            "2020-03-06 14:45:45,318 TEST : loss 0.4989779591560364 - score 0.7786\n",
            "2020-03-06 14:45:52,705 BAD EPOCHS (no improvement): 0\n",
            "2020-03-06 14:45:55,478 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 14:52:17,300 epoch 3 - iter 275/2750 - loss 0.52962901 - samples/sec: 23.89\n",
            "2020-03-06 14:58:46,376 epoch 3 - iter 550/2750 - loss 0.53025690 - samples/sec: 23.61\n",
            "2020-03-06 15:05:36,433 epoch 3 - iter 825/2750 - loss 0.52949374 - samples/sec: 22.13\n",
            "2020-03-06 15:12:05,092 epoch 3 - iter 1100/2750 - loss 0.53032441 - samples/sec: 23.38\n",
            "2020-03-06 15:18:32,259 epoch 3 - iter 1375/2750 - loss 0.52912843 - samples/sec: 23.50\n",
            "2020-03-06 15:24:59,395 epoch 3 - iter 1650/2750 - loss 0.52387075 - samples/sec: 23.59\n",
            "2020-03-06 15:31:33,602 epoch 3 - iter 1925/2750 - loss 0.52210276 - samples/sec: 23.11\n",
            "2020-03-06 15:37:51,316 epoch 3 - iter 2200/2750 - loss 0.52088904 - samples/sec: 24.19\n",
            "2020-03-06 15:43:59,444 epoch 3 - iter 2475/2750 - loss 0.51851891 - samples/sec: 24.82\n",
            "2020-03-06 15:50:19,993 epoch 3 - iter 2750/2750 - loss 0.51868849 - samples/sec: 24.05\n",
            "2020-03-06 15:50:20,169 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 15:50:20,170 EPOCH 3 done: loss 0.5187 - lr 0.1000\n",
            "2020-03-06 15:58:14,473 DEV : loss 0.47617119550704956 - score 0.7925\n",
            "2020-03-06 16:05:44,632 TEST : loss 0.48619160056114197 - score 0.7887\n",
            "2020-03-06 16:05:52,227 BAD EPOCHS (no improvement): 0\n",
            "2020-03-06 16:05:55,093 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 16:12:23,345 epoch 4 - iter 275/2750 - loss 0.49113322 - samples/sec: 23.47\n",
            "2020-03-06 16:19:20,952 epoch 4 - iter 550/2750 - loss 0.48562555 - samples/sec: 21.90\n",
            "2020-03-06 16:25:40,508 epoch 4 - iter 825/2750 - loss 0.48821102 - samples/sec: 24.01\n",
            "2020-03-06 16:31:53,642 epoch 4 - iter 1100/2750 - loss 0.49131934 - samples/sec: 24.54\n",
            "2020-03-06 16:38:18,512 epoch 4 - iter 1375/2750 - loss 0.49443614 - samples/sec: 23.87\n",
            "2020-03-06 16:44:39,742 epoch 4 - iter 1650/2750 - loss 0.49269107 - samples/sec: 24.03\n",
            "2020-03-06 16:50:59,496 epoch 4 - iter 1925/2750 - loss 0.49037990 - samples/sec: 24.11\n",
            "2020-03-06 16:57:48,166 epoch 4 - iter 2200/2750 - loss 0.48799069 - samples/sec: 22.28\n",
            "2020-03-06 17:04:09,589 epoch 4 - iter 2475/2750 - loss 0.48651532 - samples/sec: 23.82\n",
            "2020-03-06 17:10:10,989 epoch 4 - iter 2750/2750 - loss 0.48364262 - samples/sec: 25.30\n",
            "2020-03-06 17:10:11,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 17:10:11,173 EPOCH 4 done: loss 0.4836 - lr 0.1000\n",
            "2020-03-06 17:18:00,497 DEV : loss 0.3954060971736908 - score 0.8242\n",
            "2020-03-06 17:25:27,184 TEST : loss 0.4098884165287018 - score 0.8175\n",
            "2020-03-06 17:25:34,458 BAD EPOCHS (no improvement): 0\n",
            "2020-03-06 17:25:37,215 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 17:31:44,354 epoch 5 - iter 275/2750 - loss 0.45379276 - samples/sec: 24.93\n",
            "2020-03-06 17:38:27,272 epoch 5 - iter 550/2750 - loss 0.44910069 - samples/sec: 22.75\n",
            "2020-03-06 17:44:36,580 epoch 5 - iter 825/2750 - loss 0.44836385 - samples/sec: 24.76\n",
            "2020-03-06 17:50:59,816 epoch 5 - iter 1100/2750 - loss 0.44470936 - samples/sec: 23.86\n",
            "2020-03-06 17:57:31,259 epoch 5 - iter 1375/2750 - loss 0.44365263 - samples/sec: 23.33\n",
            "2020-03-06 18:04:08,303 epoch 5 - iter 1650/2750 - loss 0.43905195 - samples/sec: 22.96\n",
            "2020-03-06 18:10:30,231 epoch 5 - iter 1925/2750 - loss 0.43653536 - samples/sec: 23.85\n",
            "2020-03-06 18:17:02,456 epoch 5 - iter 2200/2750 - loss 0.43439710 - samples/sec: 23.34\n",
            "2020-03-06 18:23:13,845 epoch 5 - iter 2475/2750 - loss 0.43411271 - samples/sec: 24.69\n",
            "2020-03-06 18:29:28,164 epoch 5 - iter 2750/2750 - loss 0.43293249 - samples/sec: 24.28\n",
            "2020-03-06 18:29:28,349 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 18:29:28,350 EPOCH 5 done: loss 0.4329 - lr 0.1000\n",
            "2020-03-06 18:37:16,905 DEV : loss 0.3654356300830841 - score 0.8434\n",
            "2020-03-06 18:44:42,063 TEST : loss 0.3764975368976593 - score 0.8358\n",
            "2020-03-06 18:44:49,402 BAD EPOCHS (no improvement): 0\n",
            "2020-03-06 18:44:52,121 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 18:51:13,446 epoch 6 - iter 275/2750 - loss 0.41669655 - samples/sec: 23.96\n",
            "2020-03-06 18:57:47,009 epoch 6 - iter 550/2750 - loss 0.41830936 - samples/sec: 23.14\n",
            "2020-03-06 19:03:59,276 epoch 6 - iter 825/2750 - loss 0.41443238 - samples/sec: 24.56\n",
            "2020-03-06 19:10:27,858 epoch 6 - iter 1100/2750 - loss 0.41480508 - samples/sec: 23.43\n",
            "2020-03-06 19:16:51,211 epoch 6 - iter 1375/2750 - loss 0.41327860 - samples/sec: 23.67\n",
            "2020-03-06 19:23:15,915 epoch 6 - iter 1650/2750 - loss 0.41087509 - samples/sec: 23.69\n",
            "2020-03-06 19:29:21,858 epoch 6 - iter 1925/2750 - loss 0.40883910 - samples/sec: 24.88\n",
            "2020-03-06 19:35:39,124 epoch 6 - iter 2200/2750 - loss 0.40843446 - samples/sec: 24.08\n",
            "2020-03-06 19:42:01,973 epoch 6 - iter 2475/2750 - loss 0.40746684 - samples/sec: 23.80\n",
            "2020-03-06 19:48:12,709 epoch 6 - iter 2750/2750 - loss 0.40748177 - samples/sec: 24.78\n",
            "2020-03-06 19:48:12,896 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 19:48:12,898 EPOCH 6 done: loss 0.4075 - lr 0.1000\n",
            "2020-03-06 19:56:00,566 DEV : loss 0.36571887135505676 - score 0.8413\n",
            "2020-03-06 20:03:26,202 TEST : loss 0.37518227100372314 - score 0.8321\n",
            "2020-03-06 20:03:33,140 BAD EPOCHS (no improvement): 1\n",
            "2020-03-06 20:03:33,141 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 20:10:02,589 epoch 7 - iter 275/2750 - loss 0.39887658 - samples/sec: 23.60\n",
            "2020-03-06 20:16:30,874 epoch 7 - iter 550/2750 - loss 0.39608066 - samples/sec: 23.44\n",
            "2020-03-06 20:23:01,229 epoch 7 - iter 825/2750 - loss 0.39570045 - samples/sec: 23.36\n",
            "2020-03-06 20:29:33,166 epoch 7 - iter 1100/2750 - loss 0.39543992 - samples/sec: 23.15\n",
            "2020-03-06 20:35:45,491 epoch 7 - iter 1375/2750 - loss 0.39489273 - samples/sec: 24.61\n",
            "2020-03-06 20:42:03,756 epoch 7 - iter 1650/2750 - loss 0.39517156 - samples/sec: 24.28\n",
            "2020-03-06 20:48:21,325 epoch 7 - iter 1925/2750 - loss 0.39458086 - samples/sec: 24.38\n",
            "2020-03-06 20:54:32,258 epoch 7 - iter 2200/2750 - loss 0.39499466 - samples/sec: 24.58\n",
            "2020-03-06 21:00:51,616 epoch 7 - iter 2475/2750 - loss 0.39348681 - samples/sec: 24.05\n",
            "2020-03-06 21:07:12,684 epoch 7 - iter 2750/2750 - loss 0.39356247 - samples/sec: 23.97\n",
            "2020-03-06 21:07:12,879 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 21:07:12,881 EPOCH 7 done: loss 0.3936 - lr 0.1000\n",
            "2020-03-06 21:15:02,901 DEV : loss 0.3485885262489319 - score 0.8472\n",
            "2020-03-06 21:22:28,930 TEST : loss 0.3561328947544098 - score 0.8418\n",
            "2020-03-06 21:22:36,300 BAD EPOCHS (no improvement): 0\n",
            "2020-03-06 21:22:39,039 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 21:28:54,244 epoch 8 - iter 275/2750 - loss 0.38214110 - samples/sec: 24.38\n",
            "2020-03-06 21:35:11,437 epoch 8 - iter 550/2750 - loss 0.37953768 - samples/sec: 24.14\n",
            "2020-03-06 21:41:33,153 epoch 8 - iter 825/2750 - loss 0.38233982 - samples/sec: 23.77\n",
            "2020-03-06 21:47:53,397 epoch 8 - iter 1100/2750 - loss 0.38349245 - samples/sec: 24.01\n",
            "2020-03-06 21:54:19,094 epoch 8 - iter 1375/2750 - loss 0.38440107 - samples/sec: 23.59\n",
            "2020-03-06 22:00:31,794 epoch 8 - iter 1650/2750 - loss 0.38365548 - samples/sec: 24.47\n",
            "2020-03-06 22:07:04,823 epoch 8 - iter 1925/2750 - loss 0.38309529 - samples/sec: 23.13\n",
            "2020-03-06 22:13:20,362 epoch 8 - iter 2200/2750 - loss 0.38212403 - samples/sec: 24.38\n",
            "2020-03-06 22:19:41,362 epoch 8 - iter 2475/2750 - loss 0.38131225 - samples/sec: 24.06\n",
            "2020-03-06 22:26:18,059 epoch 8 - iter 2750/2750 - loss 0.38131629 - samples/sec: 22.97\n",
            "2020-03-06 22:26:18,252 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 22:26:18,254 EPOCH 8 done: loss 0.3813 - lr 0.1000\n",
            "2020-03-06 22:34:06,269 DEV : loss 0.34102949500083923 - score 0.8493\n",
            "2020-03-06 22:41:30,837 TEST : loss 0.3550140857696533 - score 0.8404\n",
            "2020-03-06 22:41:38,192 BAD EPOCHS (no improvement): 0\n",
            "2020-03-06 22:41:40,956 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 22:47:54,098 epoch 9 - iter 275/2750 - loss 0.37412553 - samples/sec: 24.53\n",
            "2020-03-06 22:54:31,641 epoch 9 - iter 550/2750 - loss 0.37228632 - samples/sec: 22.92\n",
            "2020-03-06 23:00:59,206 epoch 9 - iter 825/2750 - loss 0.37254596 - samples/sec: 23.64\n",
            "2020-03-06 23:07:07,273 epoch 9 - iter 1100/2750 - loss 0.37281096 - samples/sec: 24.88\n",
            "2020-03-06 23:13:21,990 epoch 9 - iter 1375/2750 - loss 0.37452904 - samples/sec: 24.42\n",
            "2020-03-06 23:20:09,137 epoch 9 - iter 1650/2750 - loss 0.37435261 - samples/sec: 22.35\n",
            "2020-03-06 23:26:12,781 epoch 9 - iter 1925/2750 - loss 0.37471364 - samples/sec: 25.10\n",
            "2020-03-06 23:32:23,146 epoch 9 - iter 2200/2750 - loss 0.37479148 - samples/sec: 24.62\n",
            "2020-03-06 23:39:03,531 epoch 9 - iter 2475/2750 - loss 0.37406010 - samples/sec: 22.74\n",
            "2020-03-06 23:45:13,502 epoch 9 - iter 2750/2750 - loss 0.37357333 - samples/sec: 24.73\n",
            "2020-03-06 23:45:13,679 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-06 23:45:13,682 EPOCH 9 done: loss 0.3736 - lr 0.1000\n",
            "2020-03-06 23:53:01,542 DEV : loss 0.31357282400131226 - score 0.8677\n",
            "2020-03-07 00:00:25,667 TEST : loss 0.32247284054756165 - score 0.8611\n",
            "2020-03-07 00:00:32,896 BAD EPOCHS (no improvement): 0\n",
            "2020-03-07 00:00:35,589 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-07 00:06:40,404 epoch 10 - iter 275/2750 - loss 0.37292337 - samples/sec: 25.08\n",
            "2020-03-07 00:13:18,859 epoch 10 - iter 550/2750 - loss 0.36621408 - samples/sec: 22.85\n",
            "2020-03-07 00:19:31,256 epoch 10 - iter 825/2750 - loss 0.36060549 - samples/sec: 24.50\n",
            "2020-03-07 00:26:00,221 epoch 10 - iter 1100/2750 - loss 0.36270235 - samples/sec: 23.39\n",
            "2020-03-07 00:32:32,852 epoch 10 - iter 1375/2750 - loss 0.36135359 - samples/sec: 23.21\n",
            "2020-03-07 00:39:06,420 epoch 10 - iter 1650/2750 - loss 0.36142052 - samples/sec: 23.16\n",
            "2020-03-07 00:45:20,522 epoch 10 - iter 1925/2750 - loss 0.36372587 - samples/sec: 24.39\n",
            "2020-03-07 00:51:43,098 epoch 10 - iter 2200/2750 - loss 0.36492146 - samples/sec: 23.94\n",
            "2020-03-07 00:58:10,637 epoch 10 - iter 2475/2750 - loss 0.36354161 - samples/sec: 23.50\n",
            "2020-03-07 01:04:25,226 epoch 10 - iter 2750/2750 - loss 0.36221177 - samples/sec: 24.33\n",
            "2020-03-07 01:04:25,411 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-07 01:04:25,412 EPOCH 10 done: loss 0.3622 - lr 0.1000\n",
            "2020-03-07 01:12:14,425 DEV : loss 0.30910471081733704 - score 0.8698\n",
            "2020-03-07 01:19:41,438 TEST : loss 0.32370784878730774 - score 0.8612\n",
            "2020-03-07 01:19:48,363 BAD EPOCHS (no improvement): 0\n",
            "2020-03-07 01:19:53,911 ----------------------------------------------------------------------------------------------------\n",
            "2020-03-07 01:19:53,912 Testing using best model ...\n",
            "2020-03-07 01:19:53,918 loading file best-model.pt\n",
            "2020-03-07 01:26:04,030 0.8612\t0.8612\t0.8612\n",
            "2020-03-07 01:26:04,032 \n",
            "MICRO_AVG: acc 0.7562 - f1-score 0.8612\n",
            "MACRO_AVG: acc 0.7562 - f1-score 0.8611500000000001\n",
            "0          tp: 4746 - fp: 772 - fn: 755 - tn: 4726 - precision: 0.8601 - recall: 0.8628 - accuracy: 0.7566 - f1-score: 0.8614\n",
            "1          tp: 4726 - fp: 755 - fn: 772 - tn: 4746 - precision: 0.8623 - recall: 0.8596 - accuracy: 0.7558 - f1-score: 0.8609\n",
            "2020-03-07 01:26:04,032 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.5849, device='cuda:0'),\n",
              "  tensor(0.4969, device='cuda:0'),\n",
              "  tensor(0.4762, device='cuda:0'),\n",
              "  tensor(0.3954, device='cuda:0'),\n",
              "  tensor(0.3654, device='cuda:0'),\n",
              "  tensor(0.3657, device='cuda:0'),\n",
              "  tensor(0.3486, device='cuda:0'),\n",
              "  tensor(0.3410, device='cuda:0'),\n",
              "  tensor(0.3136, device='cuda:0'),\n",
              "  tensor(0.3091, device='cuda:0')],\n",
              " 'dev_score_history': [0.7052,\n",
              "  0.7824,\n",
              "  0.7925,\n",
              "  0.8242,\n",
              "  0.8434,\n",
              "  0.8413,\n",
              "  0.8472,\n",
              "  0.8493,\n",
              "  0.8677,\n",
              "  0.8698],\n",
              " 'test_score': 0.8612,\n",
              " 'train_loss_history': [0.6098997605605558,\n",
              "  0.5576700229536403,\n",
              "  0.5186884905262427,\n",
              "  0.48364262035218153,\n",
              "  0.43293248575925825,\n",
              "  0.407481773996895,\n",
              "  0.39356247357346796,\n",
              "  0.38131629062782635,\n",
              "  0.37357332828099077,\n",
              "  0.3622117653489113]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WP2ZAnYh4M9",
        "colab_type": "text"
      },
      "source": [
        "### Results of model training\n",
        "\n",
        "There are several files created during model training, which will need to be saved/downloaded. The most important is 'best-model.pt' which actually contained the trained model.\n",
        "\n",
        "The final model f1 scores were around 86% for both classes on the dev and test data, which is much better than using the pretrained model. \n",
        "\n",
        "The next steps are to evaluate the trained model on subsequent data, and a template for this has been laid out below.\n",
        "\n",
        "This information will be appended to this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbbvxz_A3fUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUSVDpEOLFQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the best model\n",
        "classifier = TextClassifier.load_from_file('./best-model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycc4abS9Me1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbddlU_9LISJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create empty deque\n",
        "sentences = deque()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-EQ1l81LIds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get deque of sentences\n",
        "for text in test_text:\n",
        "    sentences.append(Sentence(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F04YKejVOstM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize values for loop\n",
        "scores = defaultdict(float)\n",
        "values = defaultdict(str)\n",
        "i = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtESxeyhOw8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict for all sentences\n",
        "classifier.predict(sentences, mini_batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNQOK8fQLIoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# deque version to generate test predictions\n",
        "while len(sentences) > 0:\n",
        "    sentence = sentences.popleft()\n",
        "    scores[i] = sentence.labels[0].score\n",
        "    values[i] = sentence.labels[0].value\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYH6sxxYO4QI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to dataframe\n",
        "df1 = pd.DataFrame({'probability': scores, 'prediction': values})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "210-kkw0O4bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7B6S6jTLI0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b64jJD1LFgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ62YgKrCZCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mex7n-J_KOZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}