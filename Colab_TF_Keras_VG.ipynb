{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Colab_TF_Keras_VG.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chuktuk/Amazon_Customer_Data/blob/master/Colab_TF_Keras_VG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_TVIoRrHnqB",
        "colab_type": "text"
      },
      "source": [
        "# Video Games Analysis with Tensorflow and Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHhFXOXHnqC",
        "colab_type": "text"
      },
      "source": [
        "## Notes\n",
        "- My tf_env contains the necessary packages and dependencies for this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRqDx7aSHnqE",
        "colab_type": "text"
      },
      "source": [
        "Data from\n",
        "> Justifying recommendations using distantly-labeled reviews and fined-grained aspects\n",
        "Jianmo Ni, Jiacheng Li, Julian McAuley\n",
        "Empirical Methods in Natural Language Processing (EMNLP), 2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sUThfhMHnqF",
        "colab_type": "code",
        "outputId": "a9da6f14-2bf4-4628-d60f-97fe7a936c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "# import packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a_Gxu85HnqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgiJ03bxHnqM",
        "colab_type": "code",
        "outputId": "e9497fa7-f225-4614-a83b-5222057a89db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 8938033469856109088\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 14305127488740761068\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 13787518889324494464\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15956161332\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 10860756586248535120\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMHOMrJBHnqP",
        "colab_type": "code",
        "outputId": "7976fb95-5abf-4b27-dce1-db4e7704fa25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "from keras import backend as K\n",
        "K.tensorflow_backend._get_available_gpus()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/job:localhost/replica:0/task:0/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP74Gu_JHnqS",
        "colab_type": "code",
        "outputId": "ac9ac07e-98bf-436c-fdb6-50fa1ee60907",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPs9r1cYHnqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrLeVZbqHnqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNE77E3CHnqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# max_features = 20000\n",
        "# # cut texts after this number of words (among top max_features most common words)\n",
        "# maxlen = 80\n",
        "# batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHJMnz9yHnqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqAE8nE7Hnql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxxNWUDxHnqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-UEelK0Hnqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8DhmVohHnqu",
        "colab_type": "code",
        "outputId": "26e5ae91-be8a-4934-a24d-44a32bd1b9d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-02 16:46:51--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154050105 (147M) [application/octet-stream]\n",
            "Saving to: ‘Video_Games_5.json.gz’\n",
            "\n",
            "Video_Games_5.json. 100%[===================>] 146.91M  11.2MB/s    in 14s     \n",
            "\n",
            "2020-03-02 16:47:06 (10.6 MB/s) - ‘Video_Games_5.json.gz’ saved [154050105/154050105]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYmWKC6_Hnqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vg = pd.read_json('Video_Games_5.json.gz', lines=True, compression='gzip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHsg7zp1Hnq1",
        "colab_type": "code",
        "outputId": "71e2a4ae-f114-4ecc-acbf-95f8d1951cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "vg.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overall</th>\n",
              "      <th>verified</th>\n",
              "      <th>reviewTime</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>vote</th>\n",
              "      <th>style</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>10 17, 2015</td>\n",
              "      <td>A1HP7NVNPFMA4N</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>Ambrosia075</td>\n",
              "      <td>This game is a bit hard to get the hang of, bu...</td>\n",
              "      <td>but when you do it's great.</td>\n",
              "      <td>1445040000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>07 27, 2015</td>\n",
              "      <td>A1JGAP0185YJI6</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>travis</td>\n",
              "      <td>I played it a while but it was alright. The st...</td>\n",
              "      <td>But in spite of that it was fun, I liked it</td>\n",
              "      <td>1437955200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>02 23, 2015</td>\n",
              "      <td>A1YJWEXHQBWK2B</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>Vincent G. Mezera</td>\n",
              "      <td>ok game.</td>\n",
              "      <td>Three Stars</td>\n",
              "      <td>1424649600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>02 20, 2015</td>\n",
              "      <td>A2204E1TH211HT</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>Grandma KR</td>\n",
              "      <td>found the game a bit too complicated, not what...</td>\n",
              "      <td>Two Stars</td>\n",
              "      <td>1424390400</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>12 25, 2014</td>\n",
              "      <td>A2RF5B5H74JLPE</td>\n",
              "      <td>0700026657</td>\n",
              "      <td>jon</td>\n",
              "      <td>great game, I love it and have played it since...</td>\n",
              "      <td>love this game</td>\n",
              "      <td>1419465600</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   overall  verified   reviewTime  ... vote style image\n",
              "0        5      True  10 17, 2015  ...  NaN   NaN   NaN\n",
              "1        4     False  07 27, 2015  ...  NaN   NaN   NaN\n",
              "2        3      True  02 23, 2015  ...  NaN   NaN   NaN\n",
              "3        2      True  02 20, 2015  ...  NaN   NaN   NaN\n",
              "4        5      True  12 25, 2014  ...  NaN   NaN   NaN\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT-waSTbHnq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vg = vg.loc[:,['overall', 'reviewText']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qid_oe-JHnq7",
        "colab_type": "code",
        "outputId": "0be3573e-1dd2-40b7-9e2f-ab8705831687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "vg.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 497577 entries, 0 to 497576\n",
            "Data columns (total 2 columns):\n",
            "overall       497577 non-null int64\n",
            "reviewText    497419 non-null object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 7.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc_8vJjxHnq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean up nan values and change datatype\n",
        "vg = vg.dropna(how='any')\n",
        "vg.loc[:,'overall'] = vg.overall.astype('int16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2CEYjpGHnrB",
        "colab_type": "code",
        "outputId": "1aeead93-2f0c-4a29-9f35-b160b36a33e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "vg.overall.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    299623\n",
              "4     93644\n",
              "3     49140\n",
              "1     30879\n",
              "2     24133\n",
              "Name: overall, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNfBMe7-HnrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# map sentiment for two-class pretrained model\n",
        "vg.loc[:,'pt_sentiment'] = vg.overall.map({1: 0, 2: 0, 3: 1, 4: 1, 5: 1}).astype('int16')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc8Z_IxdHnrJ",
        "colab_type": "code",
        "outputId": "61ddfe4e-e63f-4d19-ef7c-7769d2436d10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "vg.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 497419 entries, 0 to 497576\n",
            "Data columns (total 3 columns):\n",
            "overall         497419 non-null int16\n",
            "reviewText      497419 non-null object\n",
            "pt_sentiment    497419 non-null int16\n",
            "dtypes: int16(2), object(1)\n",
            "memory usage: 9.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZA8e2hGHnrM",
        "colab_type": "code",
        "outputId": "fcb9db50-21dc-4cf8-b441-94cded432d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "vg.pt_sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    442407\n",
              "0     55012\n",
              "Name: pt_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "safS7nS9HnrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import resample\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# down-sample to balance classes\n",
        "vg_class1 = vg[vg.pt_sentiment == 1]\n",
        "vg_class0 = vg[vg.pt_sentiment == 0]\n",
        "\n",
        "# downsample majority class\n",
        "vg_class1_down = resample(vg_class1, replace=False, n_samples=vg_class0.shape[0], random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9rQdwoHnrQ",
        "colab_type": "code",
        "outputId": "cc6b8cd7-b873-44b0-c3fa-198ddf2e12d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# concat the dfs back together\n",
        "vg_down = pd.concat([vg_class1_down, vg_class0])\n",
        "vg_down.pt_sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    55012\n",
              "0    55012\n",
              "Name: pt_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCOggBNOHnrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = vg_down.reviewText.values\n",
        "y = vg_down.pt_sentiment.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOG9f104HnrU",
        "colab_type": "code",
        "outputId": "c12bd990-4280-462b-ac7c-777bb82162c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Excellent protection for your New Nintendo 3DS. You can buy a skin for your 3ds and put this baby on, to protect it.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oazrwc9HnrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, \n",
        "          split=' ', char_level=False, oov_token=None, document_count=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAYcDL7hHnrZ",
        "colab_type": "code",
        "outputId": "e0b7cd18-2507-458a-a598-90e6f1ec55ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "type(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "keras_preprocessing.text.Tokenizer"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfRr54nPHnrb",
        "colab_type": "code",
        "outputId": "d9407fdf-2764-4d8d-f51a-6cf0f9be6abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "help(t)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on Tokenizer in module keras_preprocessing.text object:\n",
            "\n",
            "class Tokenizer(builtins.object)\n",
            " |  Text tokenization utility class.\n",
            " |  \n",
            " |  This class allows to vectorize a text corpus, by turning each\n",
            " |  text into either a sequence of integers (each integer being the index\n",
            " |  of a token in a dictionary) or into a vector where the coefficient\n",
            " |  for each token could be binary, based on word count, based on tf-idf...\n",
            " |  \n",
            " |  # Arguments\n",
            " |      num_words: the maximum number of words to keep, based\n",
            " |          on word frequency. Only the most common `num_words-1` words will\n",
            " |          be kept.\n",
            " |      filters: a string where each element is a character that will be\n",
            " |          filtered from the texts. The default is all punctuation, plus\n",
            " |          tabs and line breaks, minus the `'` character.\n",
            " |      lower: boolean. Whether to convert the texts to lowercase.\n",
            " |      split: str. Separator for word splitting.\n",
            " |      char_level: if True, every character will be treated as a token.\n",
            " |      oov_token: if given, it will be added to word_index and used to\n",
            " |          replace out-of-vocabulary words during text_to_sequence calls\n",
            " |  \n",
            " |  By default, all punctuation is removed, turning the texts into\n",
            " |  space-separated sequences of words\n",
            " |  (words maybe include the `'` character). These sequences are then\n",
            " |  split into lists of tokens. They will then be indexed or vectorized.\n",
            " |  \n",
            " |  `0` is a reserved index that won't be assigned to any word.\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ', char_level=False, oov_token=None, document_count=0, **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit_on_sequences(self, sequences)\n",
            " |      Updates internal vocabulary based on a list of sequences.\n",
            " |      \n",
            " |      Required before using `sequences_to_matrix`\n",
            " |      (if `fit_on_texts` was never called).\n",
            " |      \n",
            " |      # Arguments\n",
            " |          sequences: A list of sequence.\n",
            " |              A \"sequence\" is a list of integer word indices.\n",
            " |  \n",
            " |  fit_on_texts(self, texts)\n",
            " |      Updates internal vocabulary based on a list of texts.\n",
            " |      \n",
            " |      In the case where texts contains lists,\n",
            " |      we assume each entry of the lists to be a token.\n",
            " |      \n",
            " |      Required before using `texts_to_sequences` or `texts_to_matrix`.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          texts: can be a list of strings,\n",
            " |              a generator of strings (for memory-efficiency),\n",
            " |              or a list of list of strings.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the tokenizer configuration as Python dictionary.\n",
            " |      The word count dictionaries used by the tokenizer get serialized\n",
            " |      into plain JSON, so that the configuration can be read by other\n",
            " |      projects.\n",
            " |      \n",
            " |      # Returns\n",
            " |          A Python dictionary with the tokenizer configuration.\n",
            " |  \n",
            " |  sequences_to_matrix(self, sequences, mode='binary')\n",
            " |      Converts a list of sequences into a Numpy matrix.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          sequences: list of sequences\n",
            " |              (a sequence is a list of integer word indices).\n",
            " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\"\n",
            " |      \n",
            " |      # Returns\n",
            " |          A Numpy matrix.\n",
            " |      \n",
            " |      # Raises\n",
            " |          ValueError: In case of invalid `mode` argument,\n",
            " |              or if the Tokenizer requires to be fit to sample data.\n",
            " |  \n",
            " |  sequences_to_texts(self, sequences)\n",
            " |      Transforms each sequence into a list of text.\n",
            " |      \n",
            " |      Only top `num_words-1` most frequent words will be taken into account.\n",
            " |      Only words known by the tokenizer will be taken into account.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          sequences: A list of sequences (list of integers).\n",
            " |      \n",
            " |      # Returns\n",
            " |          A list of texts (strings)\n",
            " |  \n",
            " |  sequences_to_texts_generator(self, sequences)\n",
            " |      Transforms each sequence in `sequences` to a list of texts(strings).\n",
            " |      \n",
            " |      Each sequence has to a list of integers.\n",
            " |      In other words, sequences should be a list of sequences\n",
            " |      \n",
            " |      Only top `num_words-1` most frequent words will be taken into account.\n",
            " |      Only words known by the tokenizer will be taken into account.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          sequences: A list of sequences.\n",
            " |      \n",
            " |      # Yields\n",
            " |          Yields individual texts.\n",
            " |  \n",
            " |  texts_to_matrix(self, texts, mode='binary')\n",
            " |      Convert a list of texts to a Numpy matrix.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          texts: list of strings.\n",
            " |          mode: one of \"binary\", \"count\", \"tfidf\", \"freq\".\n",
            " |      \n",
            " |      # Returns\n",
            " |          A Numpy matrix.\n",
            " |  \n",
            " |  texts_to_sequences(self, texts)\n",
            " |      Transforms each text in texts to a sequence of integers.\n",
            " |      \n",
            " |      Only top `num_words-1` most frequent words will be taken into account.\n",
            " |      Only words known by the tokenizer will be taken into account.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          texts: A list of texts (strings).\n",
            " |      \n",
            " |      # Returns\n",
            " |          A list of sequences.\n",
            " |  \n",
            " |  texts_to_sequences_generator(self, texts)\n",
            " |      Transforms each text in `texts` to a sequence of integers.\n",
            " |      \n",
            " |      Each item in texts can also be a list,\n",
            " |      in which case we assume each item of that list to be a token.\n",
            " |      \n",
            " |      Only top `num_words-1` most frequent words will be taken into account.\n",
            " |      Only words known by the tokenizer will be taken into account.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          texts: A list of texts (strings).\n",
            " |      \n",
            " |      # Yields\n",
            " |          Yields individual sequences.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the tokenizer configuration.\n",
            " |      To load a tokenizer from a JSON string, use\n",
            " |      `keras.preprocessing.text.tokenizer_from_json(json_string)`.\n",
            " |      \n",
            " |      # Arguments\n",
            " |          **kwargs: Additional keyword arguments\n",
            " |              to be passed to `json.dumps()`.\n",
            " |      \n",
            " |      # Returns\n",
            " |          A JSON string containing the tokenizer configuration.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHofijrHHnre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the data into train/test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPErwngeHnrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDdMBLcPHnrj",
        "colab_type": "code",
        "outputId": "9999b950-0b14-4bb6-b891-8e9cb43b7b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88019"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQZja2f8Hnrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t.fit_on_texts(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IcqBmF7Hnro",
        "colab_type": "code",
        "outputId": "3ac3818d-ea1d-4549-8fc3-244d26a2e9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# summarize what was learned\n",
        "print('Number of training documents {}'.format(t.document_count))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training documents 88021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkxUWFAiHnrr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_docs = t.texts_to_matrix(X_train, mode='count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHcCAeenHnru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}